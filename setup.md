# Setup

Running the program: `cargo run`

## Libraries

### Lexer

- The tokenizer, also known as a lexical analyzer or lexer, is the component that takes raw input text and converts it into a stream of tokens. Tokens are the basic building blocks of a language's syntax, such as keywords, identifiers, literals, operators, and punctuation symbols.
